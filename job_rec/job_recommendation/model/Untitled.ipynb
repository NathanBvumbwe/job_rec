{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74661ac2-5c85-4cc1-873e-b19f5d00abd7",
   "metadata": {},
   "source": [
    "## confusion matrix for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f2e56-fe4c-42c3-943f-d41381fb583d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd50743-fd86-41ff-ad81-5c9885ff8d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967bf5f-b2e8-4c3a-bdb0-1ed993c524b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a BERT model and a test dataset\n",
    "model = 'label_encoder.pkl'\n",
    "test_loader = ...  # Your test dataset loader\n",
    "\n",
    "# Get predictions and true labels\n",
    "model.eval()\n",
    "true_labels = []\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(inputs, attention_mask=attention_mask, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e07a042-a6bd-4682-8d79-4b62fdef45b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a12ca5d0-f922-4713-9651-ce75c7c596bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created split_csv_files\\chunk_1.csv with 150 rows\n",
      "Created split_csv_files\\chunk_2.csv with 150 rows\n",
      "Created split_csv_files\\chunk_3.csv with 150 rows\n",
      "Created split_csv_files\\chunk_4.csv with 150 rows\n",
      "Created split_csv_files\\chunk_5.csv with 150 rows\n",
      "Created split_csv_files\\chunk_6.csv with 145 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_csv(input_file, rows_per_file=150, output_dir=\"split_csv_files\"):\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Read the input CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Calculate total number of rows and files needed\n",
    "    total_rows = len(df)\n",
    "    num_files = (total_rows + rows_per_file - 1) // rows_per_file\n",
    "    \n",
    "    # Split and save each chunk\n",
    "    for i in range(num_files):\n",
    "        start_idx = i * rows_per_file\n",
    "        end_idx = min((i + 1) * rows_per_file, total_rows)\n",
    "        chunk = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Generate output filename\n",
    "        output_file = os.path.join(output_dir, f\"chunk_{i+1}.csv\")\n",
    "        \n",
    "        # Save chunk to CSV\n",
    "        chunk.to_csv(output_file, index=False)\n",
    "        print(f\"Created {output_file} with {len(chunk)} rows\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"data_jobs.csv\"  # Replace with your CSV file path\n",
    "    split_csv(input_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8304701-0329-4126-a154-9df77c4c4bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
